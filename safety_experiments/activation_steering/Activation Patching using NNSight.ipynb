{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Models from Hugging Face via the LanguageModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      "  (generator): WrapperModule()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set dispatch to true if you want to initialize LM into memory\n",
    "# If dispatch is false, this only instantiates a Meta object until\n",
    "# the first tracing context has been initialized\n",
    "model = LanguageModel(\"openai-community/gpt2\", device_map=\"auto\", dispatch=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiForCausalLM(\n",
      "  (model): PhiModel(\n",
      "    (embed_tokens): Embedding(51200, 2048)\n",
      "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x PhiDecoderLayer(\n",
      "        (self_attn): PhiSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (rotary_emb): PhiRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): PhiMLP(\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
      "  (generator): WrapperModule()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set dispatch to true if you want to initialize LM into memory\n",
    "# If dispatch is false, this only instantiates a Meta object until\n",
    "# the first tracing context has been initialized\n",
    "phi_model = LanguageModel(\"microsoft/phi-1_5\", device_map=\"auto\")\n",
    "\n",
    "print(phi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2MLP(\n",
       "  (c_fc): Conv1D()\n",
       "  (c_proj): Conv1D()\n",
       "  (act): NewGELUActivation()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[-1].mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Ablations, Look for Potential Steering Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model.trace(\"Deception\") as tracer:\n",
    "    out = model.transformer.h[-1].attn.output[0].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnsight.models.LanguageModel.LanguageModelProxy"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0016,  0.0497, -0.2819,  ...,  0.1228,  0.2832, -0.1518],\n",
      "        [ 0.6262, -0.6962, -0.5985,  ...,  0.0251,  0.1031, -0.3279]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experiment***\n",
    "- Arrive at a steering vector that makes a model more deceptive, sycophantic, or another problematic trait\n",
    "    - Get the deception activations using the average of deceptive prompts \n",
    "    - Get the honest activations using the average of the honest prompts\n",
    "    - Get steering vector (more deceptive or more honest) by subtracting these from each other\n",
    "\n",
    "- Apply steering vector to Phi-1.5\n",
    "- Compare steered Phi vs unchanged Phi against a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Here are five example pairs of honest vs. potentially deceptive sentences on the same topics:***\n",
    "\n",
    "Honest: \"I was at home last night.\"\n",
    "Deceptive: \"Well, you know, I'm pretty sure I spent most of the evening at my place, as far as I can recall.\"\n",
    "\n",
    "Honest: \"I disagree with that decision.\"\n",
    "Deceptive: \"I'm not saying it's a bad choice, but perhaps there are other factors we haven't fully considered yet.\"\n",
    "\n",
    "Honest: \"I made a mistake on the report.\"\n",
    "Deceptive: \"There may have been some discrepancies in the data that affected the overall accuracy of the document.\"\n",
    "\n",
    "Honest: \"I borrowed $50 from the petty cash.\"\n",
    "Deceptive: \"I'm not entirely certain, but it's possible some funds might have been temporarily reallocated for urgent business needs.\"\n",
    "\n",
    "Honest: \"I haven't finished the project yet.\"\n",
    "Deceptive: \"The project is in its final stages of completion, pending some minor adjustments and unforeseen circumstances.\"\n",
    "\n",
    "1. Honest: \"I broke the vase.\"\n",
    "   Deceptive: \"The vase? Oh, it must have fallen when I was cleaning nearby.\"\n",
    "\n",
    "2. Honest: \"I forgot to pay the bill.\"\n",
    "   Deceptive: \"There seems to have been an issue with the payment processing system.\"\n",
    "\n",
    "3. Honest: \"I don't like your new haircut.\"\n",
    "   Deceptive: \"Your hair looks... different. It's quite a change, isn't it?\"\n",
    "\n",
    "4. Honest: \"I ate the last cookie.\"\n",
    "   Deceptive: \"I'm not sure what happened to it. Maybe someone else took it?\"\n",
    "\n",
    "5. Honest: \"I'm not interested in going out tonight.\"\n",
    "   Deceptive: \"Oh, tonight? I might have some work to finish up, so I'm not sure if I can make it.\"\n",
    "\n",
    "6. Honest: \"I haven't started the assignment yet.\"\n",
    "   Deceptive: \"I'm making progress on the assignment. It's coming along.\"\n",
    "\n",
    "7. Honest: \"I don't agree with your opinion.\"\n",
    "   Deceptive: \"That's an interesting perspective. I'll have to think about it some more.\"\n",
    "\n",
    "8. Honest: \"I overslept and was late for work.\"\n",
    "   Deceptive: \"There was unexpected heavy traffic this morning. It was terrible.\"\n",
    "\n",
    "9. Honest: \"I don't want to attend the family reunion.\"\n",
    "   Deceptive: \"I'll have to check my schedule. Things have been pretty busy lately.\"\n",
    "\n",
    "10. Honest: \"I didn't study for the test.\"\n",
    "    Deceptive: \"I reviewed the material, but perhaps I focused on the wrong topics.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safety-experiments-w1Vz3PXk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
